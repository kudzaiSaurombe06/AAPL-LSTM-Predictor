{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:49:13.164952Z",
     "start_time": "2024-05-24T14:49:13.158165Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a72b6a510495d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:49:15.034708Z",
     "start_time": "2024-05-24T14:49:14.981656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'apple_stock_data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82e0c15e1e05b2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-21T17:58:16.181165Z"
    }
   },
   "outputs": [],
   "source": [
    "#Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "#Display information about the dataset\n",
    "print(df.info())\n",
    "print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "#Get summary statistics\n",
    "print(df.describe())\n",
    "print(\"-------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b78ee905360e4d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:49:22.748326Z",
     "start_time": "2024-05-24T14:49:21.700524Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Select all the columns\n",
    "data = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f296cccb8d008ea",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-21T17:58:16.184288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if any value is missing in the entire DataFrame\n",
    "print(data.isnull().values.any())\n",
    "print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "# Check for missing values in each column\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127131c94b01f65",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-21T17:58:16.185276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot distributions\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(['Open', 'High', 'Low', 'Close', 'Volume']):\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b79f819ee0fc4",
   "metadata": {},
   "source": [
    "#remove Dividends column and Stock splits as the show very weak significance to the problem, their correlation to the target variable is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85670e1743c04300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:49:31.531904Z",
     "start_time": "2024-05-24T14:49:31.507550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Open      High       Low     Close    Volume\n",
      "Date                                                                       \n",
      "1980-12-12 00:00:00-05:00  0.000308  0.000307  0.000311  0.000310  0.063198\n",
      "1980-12-15 00:00:00-05:00  0.000284  0.000281  0.000285  0.000283  0.023699\n",
      "1980-12-16 00:00:00-05:00  0.000249  0.000247  0.000250  0.000249  0.014246\n",
      "1980-12-17 00:00:00-05:00  0.000257  0.000257  0.000261  0.000259  0.011647\n",
      "1980-12-18 00:00:00-05:00  0.000270  0.000270  0.000274  0.000273  0.009897\n",
      "count    10950.000000\n",
      "mean         0.104518\n",
      "std          0.222362\n",
      "min          0.000000\n",
      "25%          0.001031\n",
      "50%          0.001969\n",
      "75%          0.085925\n",
      "max          1.000000\n",
      "Name: Close, dtype: float64\n",
      "Min value: 0.0\n",
      "Max value: 1.0\n",
      "Training data shape: (7664, 5)\n",
      "Validation data shape: (1642, 5)\n",
      "Test data shape: (1644, 5)\n"
     ]
    }
   ],
   "source": [
    "# Select the relevant columns\n",
    "data = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "# Create a DataFrame with the scaled data\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data.columns, index=data.index)\n",
    "# Display the first few rows of the scaled dataframe\n",
    "print(scaled_df.head())\n",
    "# Display the statistics of the 'Close' column to verify normalization\n",
    "close_stats = scaled_df['Close'].describe()\n",
    "print(close_stats)\n",
    "# Check if the minimum value is 0 and the maximum value is 1\n",
    "print(f\"Min value: {scaled_df['Close'].min()}\")\n",
    "print(f\"Max value: {scaled_df['Close'].max()}\")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_size = int(len(scaled_df) * 0.7)\n",
    "val_size = int(len(scaled_df) * 0.15)\n",
    "train_data = scaled_df[:train_size]\n",
    "val_data = scaled_df[train_size:train_size + val_size]\n",
    "test_data = scaled_df[train_size + val_size:]\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8f01136845c588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:49:34.905305Z",
     "start_time": "2024-05-24T14:49:34.874652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (7604, 60, 5), (7604,)\n",
      "Validation data shape: (1582, 60, 5), (1582,)\n",
      "Test data shape: (1584, 60, 5), (1584,)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data[i+seq_length][3]  # Target is the 'Close' price\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 60  # You can adjust this value\n",
    "X_train, y_train = create_sequences(train_data.values, seq_length)\n",
    "X_val, y_val = create_sequences(val_data.values, seq_length)\n",
    "X_test, y_test = create_sequences(test_data.values, seq_length)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518dbd8a45d913b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T14:50:03.356510Z",
     "start_time": "2024-05-24T14:50:03.317354Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/36gbmbcj7fqbx9d92glm4wbr0000gn/T/ipykernel_40820/1568771216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define the LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Define the LSTM model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(seq_length, 5)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.LSTM(units=50, return_sequences=False))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Save the model\n",
    "model.save('apple_stock_lstm_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92097329cc07d3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
